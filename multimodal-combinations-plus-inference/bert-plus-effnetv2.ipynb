{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13351970,"sourceType":"datasetVersion","datasetId":8448140}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nimport joblib","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-13T11:19:25.783070Z","iopub.execute_input":"2025-10-13T11:19:25.783279Z","iopub.status.idle":"2025-10-13T11:19:28.569901Z","shell.execute_reply.started":"2025-10-13T11:19:25.783253Z","shell.execute_reply":"2025-10-13T11:19:28.569022Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import tensorflow as tf\ntf.config.set_visible_devices(tf.config.list_physical_devices('GPU')[0], 'GPU')\nimport gdown\nimport os","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T19:06:30.911862Z","iopub.execute_input":"2025-10-12T19:06:30.912669Z","iopub.status.idle":"2025-10-12T19:06:46.233675Z","shell.execute_reply.started":"2025-10-12T19:06:30.912645Z","shell.execute_reply":"2025-10-12T19:06:46.233101Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"TRAIN_IMG_FILE_ID = '1yVXguacT7OFT9wtRSW2sP0wSPlrQpFqm'\nTRAIN_TXT_FILE_ID = '1Ge21if-qDkyugYOPKSV5-4jN1AATwWw4'\nTEST_IMG_FILE_ID = '1j3-BietmC0xB0mXjbGqHXU0nviVITmHr'\nTEST_TXT_FILE_ID = '1Ge21if-qDkyugYOPKSV5-4jN1AATwWw4'\n\nprint(\"Downloading datasets from Google Drive...\")\n\n# Train dataset\ntrain_img_url = f'https://drive.google.com/uc?id={TRAIN_IMG_FILE_ID}'\ntrain_img_output = 'train_img_dataset.csv'\ngdown.download(train_img_url, train_img_output, quiet=False)\n\ntrain_txt_url = f'https://drive.google.com/uc?id={TRAIN_TXT_FILE_ID}'\ntrain_txt_output = 'train_txt_dataset.csv'\ngdown.download(train_txt_url, train_txt_output, quiet=False)\n\ndf_train_img = pd.read_csv('train_img_dataset.csv')\ndf_train_txt = pd.read_csv('train_txt_dataset.csv')\n\nfinal_train = pd.concat([df_train_img, df_train_txt], axis=1).loc[:, ~pd.concat([df_train_img, df_train_txt], axis=1).columns.duplicated()]\n\nprint(f\"Merged shape: {final_train.shape}\")\nfinal_train.to_csv('final_train_dataset.csv', index=False)\n\n# Test dataset\ntest_img_url = f'https://drive.google.com/uc?id={TEST_IMG_FILE_ID}'\ntest_img_output = 'test_img_dataset.csv'\ngdown.download(test_img_url, test_img_output, quiet=False)\n\n# test_txt_url = f'https://drive.google.com/uc?id={TEST_TXT_FILE_ID}'\n# test_txt_output = 'train_txt_dataset.csv'\n# gdown.download(test_txt_url, test_txt_output, quiet=False)\n\n# df_test_img = pd.read_csv('test_img_dataset.csv')\n# df_test_txt = pd.read_csv('test_txt_dataset.csv')\n\n# Merge horizontally, avoid duplicate columns\n# final_test = pd.concat([df_test_img, df_test_txt], axis=1).loc[:, ~pd.concat([df_test_img, df_test_txt], axis=1).columns.duplicated()]\n\n# print(f\"Merged shape: {final_test.shape}\")\n# final_test.to_csv('final_test_dataset.csv', index=False)\n\nprint(\"Download completed!\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T19:09:01.112543Z","iopub.execute_input":"2025-10-12T19:09:01.113141Z","iopub.status.idle":"2025-10-12T19:13:07.276561Z","shell.execute_reply.started":"2025-10-12T19:09:01.113118Z","shell.execute_reply":"2025-10-12T19:13:07.275924Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train = pd.read_csv(\"final_train_dataset.csv\")\ndf_test = pd.read_csv(\"test_img_dataset.csv\")\n\nprint(f\"Train shape: {df_train.shape}\")\nprint(f\"Test shape: {df_test.shape}\")\n\n# Display columns to verify structure\n# print(\"Train columns:\", df_train.columns.tolist())\n# print(\"Test columns:\", df_test.columns.tolist())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T19:13:07.277969Z","iopub.execute_input":"2025-10-12T19:13:07.278447Z","iopub.status.idle":"2025-10-12T19:13:58.013473Z","shell.execute_reply.started":"2025-10-12T19:13:07.27843Z","shell.execute_reply":"2025-10-12T19:13:58.012696Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Text preprocessing function\ndef preprocess_text(df):\n    df = df.copy()\n    \n    # Fill missing values\n    df['item_name'] = df['item_name'].fillna(\"No Data\")\n    df['bullet_points'] = df['bullet_points'].fillna(\"No Data\")\n    df['brand_name'] = df['brand_name'].fillna(\"No Data\")\n    df['unit'] = df['unit'].fillna(\"Ounce\")\n    df['value'] = df['value'].fillna(df['value'].median())\n    \n    # Clean text\n    punctuation_signs = list(\"?:!.,;\")\n    \n    for col in ['item_name', 'bullet_points']:\n        df[col] = df[col].str.replace(\"\\r\", \" \")\n        df[col] = df[col].str.replace(\"\\n\", \" \")\n        df[col] = df[col].str.replace(\"    \", \" \")\n        df[col] = df[col].str.replace('\"', '')\n        df[col] = df[col].str.lower()\n        \n        for punct_sign in punctuation_signs:\n            df[col] = df[col].str.replace(punct_sign, '')\n        df[col] = df[col].str.replace(\"'s\", \"\")\n    \n    return df\n\n# Apply preprocessing\ndf_train = preprocess_text(df_train)\ndf_test = preprocess_text(df_test)\n\nprint(\"Text preprocessing completed!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T19:14:20.93841Z","iopub.execute_input":"2025-10-12T19:14:20.93911Z","iopub.status.idle":"2025-10-12T19:14:22.768829Z","shell.execute_reply.started":"2025-10-12T19:14:20.939083Z","shell.execute_reply":"2025-10-12T19:14:22.768181Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Split the training data into train/validation sets\nX_temp = df_train.drop(['price'], axis=1)\ny_temp = df_train['price']\n\nX_train, X_val, y_train, y_val = train_test_split(\n    X_temp, y_temp, \n    test_size=0.1, \n    random_state=42\n)\n\nprint(f\"Training set: {X_train.shape[0]} samples\")\nprint(f\"Validation set: {X_val.shape[0]} samples\")\nprint(f\"Test set: {df_test.shape[0]} samples\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T19:14:27.254657Z","iopub.execute_input":"2025-10-12T19:14:27.255237Z","iopub.status.idle":"2025-10-12T19:14:28.196297Z","shell.execute_reply.started":"2025-10-12T19:14:27.255213Z","shell.execute_reply":"2025-10-12T19:14:28.195597Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Identify image embedding columns (assuming they start with 'embedding_' or similar)\nimg_embedding_cols = [col for col in X_train.columns if col.startswith('dim_')]\ntxt_embedding_cols = [col for col in X_train.columns if col.startswith('embedding_')]\n\nprint(f\"Found {len(img_embedding_cols)} embedding columns\")\nprint(f\"Found {len(txt_embedding_cols)} embedding columns\")\nprint(\"First 5 img embedding columns:\", img_embedding_cols[:5])\nprint(\"First 5 text embedding columns:\", txt_embedding_cols[:5])\n\n# Extract embeddings\nX_train_img_embeddings = X_train[img_embedding_cols].values\nX_val_img_embeddings = X_val[img_embedding_cols].values\nX_train_txt_embeddings = X_train[txt_embedding_cols].values\nX_val_txt_embeddings = X_val[txt_embedding_cols].values\n# X_test_img_embeddings = df_test[img_embedding_cols].values\n# X_test_txt_embeddings = df_test[txt_embedding_cols].values\n\nprint(f\"Train img embeddings shape: {X_train_img_embeddings.shape}\")\nprint(f\"Val img embeddings shape: {X_val_img_embeddings.shape}\")\nprint(f\"Train txt embeddings shape: {X_train_txt_embeddings.shape}\")\nprint(f\"Val txt embeddings shape: {X_val_txt_embeddings.shape}\")\n# print(f\"Test img embeddings shape: {X_test_img_embeddings.shape}\")\n# print(f\"Test txt embeddings shape: {X_test_txt_embeddings.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T19:15:38.120981Z","iopub.execute_input":"2025-10-12T19:15:38.121248Z","iopub.status.idle":"2025-10-12T19:15:38.531738Z","shell.execute_reply.started":"2025-10-12T19:15:38.121229Z","shell.execute_reply":"2025-10-12T19:15:38.530968Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Combine text features\nX_train_text = X_train['item_name'] + ' ' + X_train['bullet_points']\nX_val_text = X_val['item_name'] + ' ' + X_val['bullet_points']\nX_test_text = df_test['item_name'] + ' ' + df_test['bullet_points']\n\n# TF-IDF Vectorization\ntfidf = TfidfVectorizer(stop_words='english', ngram_range=(1, 2), min_df=5, max_features=2000)\nprint(\"Fitting TF-IDF...\")\n\nX_train_tfidf = tfidf.fit_transform(X_train_text)\nX_val_tfidf = tfidf.transform(X_val_text)\n# X_test_tfidf = tfidf.transform(X_test_text)\n\nprint(f\"TF-IDF train shape: {X_train_tfidf.shape}\")\nprint(f\"TF-IDF val shape: {X_val_tfidf.shape}\")\n# print(f\"TF-IDF test shape: {X_test_tfidf.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T19:15:49.619416Z","iopub.execute_input":"2025-10-12T19:15:49.619674Z","iopub.status.idle":"2025-10-12T19:15:58.75614Z","shell.execute_reply.started":"2025-10-12T19:15:49.619657Z","shell.execute_reply":"2025-10-12T19:15:58.755415Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Reduce TF-IDF dimensions\nsvd_tfidf = TruncatedSVD(n_components=1000, random_state=42)\nsvd_img_embed = TruncatedSVD(n_components=500, random_state=42)\nsvd_txt_embed = TruncatedSVD(n_components=300, random_state=42)\nprint(\"Applying dimensionality reduction...\")\n\nX_train_tfidf_reduced = svd_tfidf.fit_transform(X_train_tfidf)\nX_val_tfidf_reduced = svd_tfidf.transform(X_val_tfidf)\n# X_test_tfidf_reduced = svd_tfidf.transform(X_test_tfidf)\n\nX_train_img_embeddings_reduced = svd_img_embed.fit_transform(X_train_img_embeddings)\nX_val_img_embeddings_reduced = svd_img_embed.transform(X_val_img_embeddings)\n# X_test_img_embeddings_reduced = svd_img_embed.transform(X_test_img_embeddings)\n\nX_train_txt_embeddings_reduced = svd_txt_embed.fit_transform(X_train_txt_embeddings)\nX_val_txt_embeddings_reduced = svd_txt_embed.transform(X_val_txt_embeddings)\n# X_test_txt_embeddings_reduced = svd_txt_embed.transform(X_test_txt_embeddings)\n\n\nprint(f\"Reduced TF-IDF train shape: {X_train_tfidf_reduced.shape}\")\nprint(f\"Reduced TF-IDF val shape: {X_val_tfidf_reduced.shape}\")\n# print(f\"Reduced TF-IDF test shape: {X_test_tfidf_reduced.shape}\")\n\nprint(f\"Reduced Img Embeddings train shape: {X_train_img_embeddings_reduced.shape}\")\nprint(f\"Reduced Img Embeddings val shape: {X_val_img_embeddings_reduced.shape}\")\n# print(f\"Reduced Img Embeddings test shape: {X_test_img_embeddings_reduced.shape}\")\n\nprint(f\"Reduced Txt Embeddings train shape: {X_train_txt_embeddings_reduced.shape}\")\nprint(f\"Reduced Txt Embeddings val shape: {X_val_txt_embeddings_reduced.shape}\")\n# print(f\"Reduced Txt Embeddings test shape: {X_test_txt_embeddings_reduced.shape}\")\n\n\nprint(f\"Explained variance ratio: {svd_tfidf.explained_variance_ratio_.sum():.4f}\")\nprint(f\"Explained variance ratio: {svd_img_embed.explained_variance_ratio_.sum():.4f}\")\nprint(f\"Explained variance ratio: {svd_txt_embed.explained_variance_ratio_.sum():.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T19:30:49.749051Z","iopub.execute_input":"2025-10-12T19:30:49.749549Z","iopub.status.idle":"2025-10-12T19:31:46.690018Z","shell.execute_reply.started":"2025-10-12T19:30:49.749526Z","shell.execute_reply":"2025-10-12T19:31:46.689218Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Extract numerical features\nX_train_numerical = X_train[['value']].values\nX_val_numerical = X_val[['value']].values\n# X_test_numerical = df_test[['value']].values\n\nprint(\"Combining all features...\")\n# Combine TF-IDF + Numerical + Image Embeddings\nX_train_combined = np.hstack([\n    X_train_tfidf_reduced, \n    X_train_numerical, \n    X_train_img_embeddings_reduced,\n    X_train_txt_embeddings_reduced\n])\n\nX_val_combined = np.hstack([\n    X_val_tfidf_reduced, \n    X_val_numerical, \n    X_val_img_embeddings_reduced,\n    X_val_txt_embeddings_reduced\n])\n\n# X_test_combined = np.hstack([\n#     X_test_tfidf_reduced, \n#     X_test_numerical, \n#     X_test_img_embeddings_reduced,\n#     X_test_txt_embeddings_reduced\n# ])\n\nprint(f\"Combined train shape: {X_train_combined.shape}\")\nprint(f\"Combined val shape: {X_val_combined.shape}\")\n# print(f\"Combined test shape: {X_test_combined.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T19:31:51.345016Z","iopub.execute_input":"2025-10-12T19:31:51.345274Z","iopub.status.idle":"2025-10-12T19:31:51.626813Z","shell.execute_reply.started":"2025-10-12T19:31:51.345256Z","shell.execute_reply":"2025-10-12T19:31:51.626191Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train Linear Regression\nfrom xgboost import XGBRegressor\nfrom sklearn.linear_model import BayesianRidge\nfrom lightgbm import LGBMRegressor\nprint(\"Training Linear Regression model...\")\n# model = LinearRegression()\nmodel = LGBMRegressor(n_estimators=500, random_state=42)\nmodel.fit(X_train_combined, y_train)\n\nprint(\"Model training completed!\")\n\n# Make predictions on validation set\ny_val_pred = model.predict(X_val_combined)\n\n# Calculate metrics\nmse = mean_squared_error(y_val, y_val_pred)\nmae = mean_absolute_error(y_val, y_val_pred)\nr2 = r2_score(y_val, y_val_pred)\n\nprint(f\"Validation Metrics:\")\nprint(f\"MSE: {mse:.4f}\")\nprint(f\"MAE: {mae:.4f}\")\nprint(f\"R² Score: {r2:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T19:32:27.405775Z","iopub.execute_input":"2025-10-12T19:32:27.406335Z","iopub.status.idle":"2025-10-12T19:35:15.580368Z","shell.execute_reply.started":"2025-10-12T19:32:27.406304Z","shell.execute_reply":"2025-10-12T19:35:15.57955Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create validation results dataframe\nval_results = pd.DataFrame({\n    'sample_id': X_val['sample_id'],\n    'actual_price': y_val,\n    'predicted_price': y_val_pred\n})\n\n# Save validation results\nval_results.to_csv('/kaggle/working/validation_predictions.csv', index=False)\nprint(\"Validation predictions saved to 'validation_predictions.csv'\")\nprint(f\"Validation results shape: {val_results.shape}\")\nprint(val_results.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T19:35:29.737479Z","iopub.execute_input":"2025-10-12T19:35:29.738331Z","iopub.status.idle":"2025-10-12T19:35:29.761693Z","shell.execute_reply.started":"2025-10-12T19:35:29.738301Z","shell.execute_reply":"2025-10-12T19:35:29.761164Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save the model and preprocessing objects\njoblib.dump(model, 'linear_regression_combined_model.pkl')\njoblib.dump(tfidf, 'tfidf_vectorizer.pkl')\njoblib.dump(svd_tfidf, 'svd_tfidf_reducer.pkl')\njoblib.dump(svd_embed, 'svd_embed_reducer.pkl')\n\nprint(\"Model and preprocessing objects saved!\")\nprint(\"Files saved:\")\nprint(\"- linear_regression_combined_model.pkl\")\nprint(\"- tfidf_vectorizer.pkl\")\nprint(\"- svd_reducer.pkl\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Make predictions on test set\nprint(\"Making predictions on test set...\")\ny_test_pred = model.predict(X_test_combined)\n\n# Create submission file\nsubmission_df = pd.DataFrame({\n    'sample_id': df_test['sample_id'],\n    'pred_price': y_test_pred\n})\n\n# Save submission file\nsubmission_df.to_csv('submission_final.csv', index=False)\nprint(\"Test predictions saved to 'submission_final.csv'\")\nprint(f\"Submission file shape: {submission_df.shape}\")\nprint(submission_df.head())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"=\" * 50)\nprint(\"RESULTS SUMMARY\")\nprint(\"=\" * 50)\nprint(f\"Training samples: {X_train.shape[0]}\")\nprint(f\"Validation samples: {X_val.shape[0]}\")\nprint(f\"Test samples: {df_test.shape[0]}\")\nprint(f\"Final feature dimensions: {X_train_combined.shape[1]}\")\nprint(f\"Validation R² Score: {r2:.4f}\")\nprint(f\"Validation MAE: {mae:.4f}\")\nprint(\"\\nFiles created:\")\nprint(\"- validation_predictions.csv (actual vs predicted for validation set)\")\nprint(\"- submission_final.csv (test predictions for submission)\")\nprint(\"- linear_regression_combined_model.pkl\")\nprint(\"- tfidf_vectorizer.pkl\")\nprint(\"- svd_reducer.pkl\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}